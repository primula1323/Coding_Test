---
title: "reghw6"
author: "Na SeungChan"
mainfont: UnDotum
monofont: UnShinmun
output:
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library('tidyverse')
library('MPV')
library('glmnet')
set.seed(100)
```



## Q1

### Data Importing

```{r}
datasetq1 <- MPV::table.b1
modelq1_all <- lm(y ~ x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9, datasetq1)
summary(modelq1_all)
```


### (a)

```{r}
modelq1_forward <- olsrr::ols_step_forward_p(modelq1_all, detail = T)
modelq1_forward
```


### (b)

```{r}
modelq1_back <- olsrr::ols_step_backward_p(modelq1_all, detail = T)
modelq1_back
```


### (c)

```{r}
modelq1_stepwise <- olsrr::ols_step_both_p(modelq1_all, detail = T)
modelq1_stepwise
```


### (d)

Forward selection selected x2, x7, x8, x9 and backward elimination removed x5, x1, x6, x3, x4(namely, final model from backward elinimation is alse y ~ x2 + x7 + x8 + x9). However, stepwise selection added only x2, x8, x7, except for x9.



## Q2

### Data Importing

```{r}
datasetq2_temp <- rbind(c(1, 53), c(1, 56), c(1, 57), c(0, 63), c(0, 66), c(0, 67), c(0, 67), c(0, 67), c(0, 68), c(0, 69), c(0, 70), c(1, 70), c(1, 70), c(1, 70), c(0, 72), c(0, 73), c(0, 75), c(1, 75), c(0, 76), c(0, 76), c(0, 78), c(0, 79), c(0, 80), c(0,81))
datasetq2 <- as_tibble(datasetq2_temp) %>% 
  rename(Failure = V1, Temperature = V2)
```


### (a)

```{r}
logistic_model_q2 <- glm(Failure ~ Temperature, data = datasetq2, family = "binomial")
summary(logistic_model_q2)

ggplot(data = datasetq2, aes(x = Temperature, y = Failure)) +
  geom_point() + 
  stat_smooth(method = 'glm', se = F, method.args = list(family = binomial))
```

logit function : p_hat = (1+exp(-10.87535+0.17132*Temperature))^(-1)

overall this model captures increase in failure as temperature decrease;but some failure at temperature = 70 and 75 could be less explainable points.


## (b)

```{r}
Pr = 7/24
odds_1 = Pr/(1-Pr)
odds_2 = (1-Pr)/Pr
odds_r = odds_1/odds_2
```


Beta from logistic regression model can be explained by the increase in odds-ratio according to increase in x.

## (c)

```{r}
predict_50 <- 1/(1+exp(-10.87535+0.17132*50))
predict_50
```


## (d)

```{r}
logistic_model_q2 <- glm(Failure ~ Temperature + I(Temperature^2), data = datasetq2, family = "binomial")
summary(logistic_model_q2)
```

increase in P-value



## Q3

### Data Importing

```{r}
group_control <- c(27, 32, 34, 33, 36, 34, 33, 30, 24, 31)
group_80 <- c(33, 33, 35, 33, 36, 26, 27, 31, 32, 29)
group_160 <- c(29, 29, 23, 27, 30, 31, 30, 26, 29, 29)
group_235 <- c(23, 21, 7, 12, 27, 16, 13, 15, 21, 17)
group_310 <- c(6, 6, 7, 0, 15, 5, 6, 4, 6, 5)

datasetq3_temp <- c(group_control, group_80, group_160, group_235, group_310)
datasetq3 <- as_tibble(datasetq3_temp) %>%
  mutate(rn = row_number(), is80 = ifelse(11 <= rn&rn <= 20, 1, 0)) %>%
  mutate(is160 = ifelse(21 <=rn&rn <= 30, 1, 0), is235 = ifelse(31 <=rn&rn <= 40, 1, 0)) %>%
  mutate(is310 = ifelse(41 <=rn&rn <= 50, 1, 0))#Dummy coding
```


### Analysis

'the number of offsprings' follows poisson random variable (lambda)*n. so regression
by poisson-log regression.

```{r}
logistic_model_q3 <- glm(value ~ is80 + is160 + is235 + is310 , data = datasetq3, family = "poisson")
summary(logistic_model_q3)
```

From p-value, the effect of is235 and is310 is significant.

